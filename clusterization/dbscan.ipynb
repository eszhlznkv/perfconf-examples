{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de33f4a-3cb7-41ba-991c-e3a71f161d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6868b102-17d4-4f75-a2ec-2dc1d1b6ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных из CSV файлов\n",
    "df1 = pd.read_csv('/Users/evgenii/Documents/GitHub/perfconf/perfcong-jmeter-examples/clusterization/data/baseline_more_dispertion/raw_data.csv')\n",
    "df2 = pd.read_csv('/Users/evgenii/Documents/GitHub/perfconf/perfcong-jmeter-examples/clusterization/data/new_release/raw_data.csv')\n",
    "\n",
    "# Преобразование startTime в формат даты\n",
    "df1['startTime'] = pd.to_datetime(df1['startTime'], unit='ms')\n",
    "df2['startTime'] = pd.to_datetime(df2['startTime'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c2d077-c0b5-462c-8780-4d9d6b94b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластеризация первого временного ряда:\n"
     ]
    },
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Int64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m dbscan \u001b[38;5;241m=\u001b[39m DBSCAN(eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mКластеризация первого временного ряда:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m num_clusters1_kmeans, centers1_kmeans \u001b[38;5;241m=\u001b[39m cluster_and_plot(df1, kmeans, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK-Means Clustering for Series 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m num_clusters1_dbscan, centers1_dbscan \u001b[38;5;241m=\u001b[39m cluster_and_plot(df1, dbscan, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDBSCAN Clustering for Series 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Кластеризация и визуализация для второго временного ряда\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m, in \u001b[0;36mcluster_and_plot\u001b[0;34m(df, algorithm, title)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcluster_and_plot\u001b[39m(df, algorithm, title):\n\u001b[1;32m     14\u001b[0m     X \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstartTime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponseTime\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m---> 15\u001b[0m     clustering \u001b[38;5;241m=\u001b[39m algorithm\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m     17\u001b[0m     centers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# K-means\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/perfconf/perfcong-jmeter-examples/clusterization/env/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/perfconf/perfcong-jmeter-examples/clusterization/env/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1481\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \n\u001b[1;32m   1457\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1481\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1482\u001b[0m         X,\n\u001b[1;32m   1483\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1484\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[1;32m   1485\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1486\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_x,\n\u001b[1;32m   1487\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1488\u001b[0m     )\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1492\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/Documents/GitHub/perfconf/perfcong-jmeter-examples/clusterization/env/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Documents/GitHub/perfconf/perfcong-jmeter-examples/clusterization/env/lib/python3.12/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    876\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    877\u001b[0m )\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 879\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[1;32m    882\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[0;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Int64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>)"
     ]
    }
   ],
   "source": [
    "# # Функция для загрузки и подготовки данных\n",
    "# def load_and_prepare_data(file_path):\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     df['startTime'] = pd.to_datetime(df['startTime'])\n",
    "#     df['timestamp'] = (df['startTime'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "#     return df\n",
    "\n",
    "# # Загрузка данных из CSV файлов\n",
    "# df1 = load_and_prepare_data('timeseries1.csv')\n",
    "# df2 = load_and_prepare_data('timeseries2.csv')\n",
    "\n",
    "# Функция для кластеризации и визуализации\n",
    "def cluster_and_plot(df, algorithm, title):\n",
    "    X = df[['startTime', 'responseTime']]\n",
    "    clustering = algorithm.fit(X)\n",
    "    \n",
    "    centers = []\n",
    "    # K-means\n",
    "    if hasattr(clustering, 'cluster_centers_'):\n",
    "        centers = clustering.cluster_centers_\n",
    "        labels = clustering.labels_\n",
    "        num_clusters = len(centers)\n",
    "    # DBSCAN\n",
    "    else:\n",
    "        labels = clustering.labels_\n",
    "        unique_labels = set(labels)\n",
    "        num_clusters = len(unique_labels) - (1 if -1 in labels else 0)\n",
    "        core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
    "        core_samples_mask[clustering.core_sample_indices_] = True\n",
    "        core_samples = X[core_samples_mask]\n",
    "        if len(core_samples) > 0:\n",
    "            centers = np.array([core_samples[labels == label].mean(axis=0) for label in unique_labels if label != -1])\n",
    "    \n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.scatterplot(x='startTime', y='responseTime', hue=labels, palette='viridis', data=df, legend='full')\n",
    "    if len(centers) > 0:\n",
    "        plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X', label='Centers')\n",
    "    plt.title(f'{title} - {num_clusters} clusters')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return num_clusters, centers\n",
    "\n",
    "# Функция для сравнения кластеров\n",
    "def compare_clusters(num_clusters1, centers1, num_clusters2, centers2, threshold=0.2):\n",
    "    if num_clusters1 != num_clusters2:\n",
    "        print(f\"Количество кластеров отличается: {num_clusters1} vs {num_clusters2}\")\n",
    "    else:\n",
    "        print(f\"Количество кластеров одинаковое: {num_clusters1}\")\n",
    "\n",
    "    if len(centers1) > 0 and len(centers2) > 0:\n",
    "        for i in range(min(num_clusters1, num_clusters2)):\n",
    "            dist = np.linalg.norm(centers1[i] - centers2[i])\n",
    "            if dist > threshold:\n",
    "                print(f\"Центры кластеров {i} отличаются больше чем на {threshold*100}%: {centers1[i]} vs {centers2[i]} (расстояние = {dist})\")\n",
    "            else:\n",
    "                print(f\"Центры кластеров {i} похожи: {centers1[i]} vs {centers2[i]} (расстояние = {dist})\")\n",
    "\n",
    "# Кластеризация и визуализация для первого временного ряда\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
    "\n",
    "print(\"Кластеризация первого временного ряда:\")\n",
    "num_clusters1_kmeans, centers1_kmeans = cluster_and_plot(df1, kmeans, \"K-Means Clustering for Series 1\")\n",
    "num_clusters1_dbscan, centers1_dbscan = cluster_and_plot(df1, dbscan, \"DBSCAN Clustering for Series 1\")\n",
    "\n",
    "# Кластеризация и визуализация для второго временного ряда\n",
    "print(\"Кластеризация второго временного ряда:\")\n",
    "num_clusters2_kmeans, centers2_kmeans = cluster_and_plot(df2, kmeans, \"K-Means Clustering for Series 2\")\n",
    "num_clusters2_dbscan, centers2_dbscan = cluster_and_plot(df2, dbscan, \"DBSCAN Clustering for Series 2\")\n",
    "\n",
    "# Наложение временных рядов друг на друга\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df1['startTime'], df1['responseTime'], label='Series 1', color='blue')\n",
    "plt.plot(df2['startTime'], df2['responseTime'], label='Series 2', color='orange')\n",
    "plt.title('Overlay of Two Time Series')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Сравнение кластеров\n",
    "print(\"\\nСравнение кластеров K-Means:\")\n",
    "compare_clusters(num_clusters1_kmeans, centers1_kmeans, num_clusters2_kmeans, centers2_kmeans)\n",
    "\n",
    "print(\"\\nСравнение кластеров DBSCAN:\")\n",
    "compare_clusters(num_clusters1_dbscan, centers1_dbscan, num_clusters2_dbscan, centers2_dbscan)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
